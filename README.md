üá≤üáæ Malay-to-Code: A Fine-Tuning Project for Malay Natural Language Programming
A research initiative to fine-tune a Large Language Model (LLM) to generate programming code from commands in Bahasa Melayu.

üí° Project Overview
This project aims to bridge the linguistic gap in AI-driven software development. We are creating a novel, high-quality dataset of programming prompts in Bahasa Melayu to fine-tune a large language model. By doing so, we intend to lower the barrier to entry for aspiring Malaysian developers, allowing them to express their programming intent in their native language and see it translated into functional code.

ü§î The Problem
The majority of large language models are trained on vast datasets of English text. This creates a significant challenge for non-English speaking communities, as the models often struggle to understand the nuances, slang, and cultural context of other languages, including Bahasa Melayu. For novice programmers in Malaysia, this adds a layer of cognitive load: they must not only learn programming logic and syntax but also translate their thoughts into English before they can use AI-assisted coding tools effectively.

‚úÖ Our Solution
Our approach directly addresses this problem by focusing on language localization. We will:

Generate a Dataset: Create a parallel dataset by machine-translating common English programming prompts into Bahasa Melayu.

Validate the Dataset: Engage with a panel of linguistic and NLP experts to validate the accuracy, clarity, and naturalness of the translated dataset.

Fine-Tune the LLM: Use this validated dataset to fine-tune a large language model, teaching it to understand and execute coding commands given in Malay.

Evaluate Performance: Rigorously test the fine-tuned model to measure its performance against the original model and validate its effectiveness.

üõ†Ô∏è Methodology: The Three Stages
The project is structured into three clear stages:

Stage 1: Data Generation & Initial Translation
We have utilized automated translation tools to convert a large collection of programming prompts from English to Malay.

Stage 2: Expert Validation (Where You Come In!)
This is the most critical stage of our work. The quality of our fine-tuning model is entirely dependent on the quality of the data it learns from. We are inviting researchers and academics with expertise in NLP and computational linguistics to help us validate our machine-translated dataset.

The Validation Process is Simple and Efficient:

You will be provided with a link to a Google Form.

The form presents a series of translated Malay prompts.

Your task is to rate the linguistic quality and clarity of each translation on a simple 1-5 scale.

There is an optional text box to suggest improvements for any sentences that feel unnatural or inaccurate.

Your contribution is invaluable, and in sincere appreciation for your time and expertise, we will formally acknowledge you and your affiliation in our final research paper.

Stage 3: Fine-Tuning & Model Evaluation
Once the dataset is validated, we will proceed with the fine-tuning process and report on our model's performance.

ü§ù How to Collaborate
If you are interested in contributing to this project, please reach out to us directly via email. Your perspective would be a tremendous asset to our work.

‚úâÔ∏è Contact Us
Ivan Char Cheng Jun

University of Nottingham Malaysia

Cham Jin Jie

University of Nottingham Malaysia

Supervisor: Dr. Simon Lau Boung Yew

School of Computer Science

University of Nottingham Malaysia
