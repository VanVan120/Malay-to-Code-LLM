# üá≤üáæ Malay-to-Code: Fine-Tuning LLMs for Bahasa Melayu Programming

[![Project Status: Research](https://img.shields.io/badge/status-research-blue)]()
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)]()

A research initiative to fine-tune a Large Language Model (LLM) for generating programming code from natural language commands in Bahasa Melayu (Malay).

---

## üí° Project Overview

The goal of this project is to bridge the linguistic gap in AI-driven software development. We are creating a novel, high-quality dataset of programming prompts in Bahasa Melayu to fine-tune a large language model (LLM), enabling it to understand and execute coding instructions provided in Malay.

---

## ü§î The Problem

Most large language models are trained predominantly on English text. As a result, non-English speaking communities‚Äîlike those who use Bahasa Melayu‚Äîface significant challenges using these models, as they often struggle to understand and generate code from prompts in other languages.

---

## ‚úÖ Our Solution

We aim to localize LLM capabilities for Bahasa Melayu by:

- **Generating a Dataset:** Creating a parallel dataset by machine-translating common English programming prompts into Bahasa Melayu.
- **Validating the Dataset:** Collaborating with linguistic and NLP experts to ensure translations are accurate, clear, and natural.
- **Fine-Tuning the Model:** Using the validated dataset to fine-tune a large language model so it can understand and execute Malay programming commands.
- **Evaluating Performance:** Rigorously testing the fine-tuned model to measure improvements over baseline models.

---

## üõ†Ô∏è Methodology: Three Stages

### 1. Data Generation & Translation

- Used automated translation tools to convert a large collection of programming prompts from English to Malay.

### 2. Expert Validation **(We Need Your Help!)**

- Experts and academics review the translations for linguistic quality and clarity.
- **Validation Process:**  
  1. Access a Google Form with translated Malay prompts.
  2. Rate each translation on a 1‚Äì5 scale for quality and clarity.
  3. Optionally, suggest improvements for any sentences.

> **Your contribution is invaluable!** All contributors and their affiliations will be formally acknowledged in our final research publication.

### 3. Fine-Tuning & Evaluation

- Fine-tune the LLM using the validated dataset.
- Report and analyze the model's performance.

---

## ü§ù How to Collaborate

We welcome collaborators and contributors, especially those with expertise in linguistics, natural language processing, or software engineering.

- **Interested?** Reach out to us via email (see below).
- **Contribution:** Data validation, model training, evaluation, or research collaboration.
- **Recognition:** Contributors will be acknowledged in publications.

---

## ‚úâÔ∏è Contact Us

**Ivan Char Cheng Jun, hfyic3@nottingham.edu.my**  
University of Nottingham Malaysia

**Cham Jin Jie, hfyjc23@nottingham.edu.my**  
University of Nottingham Malaysia

**Supervisor:** Dr. Simon Lau Boung Yew, simon.lau@nottingham.edu.my  
School of Computer Science, University of Nottingham Malaysia

---

Thank you for your interest in supporting AI localization for Bahasa Melayu and making programming more accessible for everyone!
